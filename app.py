# app.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# Import from src
from src.kmeans_custom import KMeansCustom
from src.dbscan_library import DBSCANLibrary
from src.evaluation import ClusterEvaluator
from src.visualization import ClusterVisualizer

# HÃ m váº½ ranh giá»›i quyáº¿t Ä‘á»‹nh
def plot_decision_boundary(ax, xx, yy, labels_grid, cmap):
    """Váº½ ranh giá»›i quyáº¿t Ä‘á»‹nh trÃªn lÆ°á»›i."""
    ax.contourf(xx, yy, labels_grid.reshape(xx.shape), alpha=0.3, cmap=cmap)

# Khá»Ÿi táº¡o session state Ä‘á»ƒ lÆ°u trá»¯ káº¿t quáº£ Ä‘Ã¡nh giÃ¡
if 'eval_history' not in st.session_state:
    st.session_state.eval_history = {}

st.title("PhÃ¢n cá»¥m báº±ng K-Means hoáº·c DBSCAN")

# 1. Upload CSV file
uploaded = st.sidebar.file_uploader("Upload CSV for clustering", type=["csv"])
if not uploaded:
    st.sidebar.warning("Please upload a CSV file to proceed.")
    st.stop()

df = pd.read_csv(uploaded)
st.write("**Uploaded Data Preview**")
st.write(df.head())

# 2. Feature selection
cols = st.sidebar.multiselect(
    "Select columns for clustering", df.columns.tolist(), default=["Age", "Annual Income (k$)", "Spending Score (1-100)"]
)
if len(cols) < 2:
    st.sidebar.warning("Please select at least 2 columns.")
    st.stop()

# 2.1 Handle features: Numeric and categorical via one-hot encoding
df_selected = df[cols]
df_processed = pd.get_dummies(df_selected, drop_first=True)
X_raw = df_processed.values
X = StandardScaler().fit_transform(X_raw)
st.write(f"**Selected Features (after preprocessing)**: {df_processed.columns.tolist()}")

# 3. Algorithm options
method = st.sidebar.selectbox("Clustering Method", ["K-Means", "DBSCAN"])
if method == "K-Means":
    algo = st.sidebar.selectbox("Algorithm", ["Custom", "Scikit-learn"])
    k = st.sidebar.slider("K clusters", 2, 10, 5)
    max_iters = st.sidebar.number_input("Max iterations", 10, 1000, 300)
    tol = st.sidebar.number_input("Tolerance", 1e-6, 1e-1, 1e-4, format="%.1e")
    random_state = st.sidebar.number_input("Random state", 0, 9999, 42)
else:  # DBSCAN
    algo = "DBSCAN"
    eps = st.sidebar.number_input("Epsilon (eps)", 0.1, 2.0, 0.5, step=0.1)
    min_samples = st.sidebar.number_input("Min samples", 2, 20, 5)
    random_state = None  # DBSCAN khÃ´ng cáº§n random_state

# Danh sÃ¡ch cÃ¡c Ä‘á»™ Ä‘o Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ (chá»‰ láº¥y Silhouette Score vÃ  Davies-Bouldin Index)
metrics_to_compare = [
    "Silhouette Score",
    "Davies-Bouldin Index"
]

if st.sidebar.button("Run Clustering"):
    # 4. Run clustering
    if method == "K-Means":
        if algo == "Custom":
            km = KMeansCustom(k=k, max_iters=max_iters, tol=tol, random_state=random_state)
            labels, centers = km.fit(X)
            method_name = "K-Means (Custom)"
        else:
            km = KMeans(n_clusters=k, max_iter=max_iters, tol=tol,
                        random_state=random_state, n_init=10)
            labels = km.fit_predict(X)
            centers = km.cluster_centers_
            method_name = "K-Means (Scikit-learn)"
    else:  # DBSCAN
        dbscan = DBSCANLibrary(eps=eps, min_samples=min_samples)
        labels = dbscan.fit(X)
        centers = None  # DBSCAN khÃ´ng cÃ³ tÃ¢m cá»¥m
        method_name = f"DBSCAN (eps={eps}, min_samples={min_samples})"

    # 5. Evaluation using ClusterEvaluator
    evaluator = ClusterEvaluator()
    eval_results = evaluator.evaluate(X, labels, centroids=centers, method_name=method_name)
    
    # LÆ°u káº¿t quáº£ Ä‘Ã¡nh giÃ¡ vÃ o session state
    st.session_state.eval_history[method_name] = eval_results

    st.subheader("ğŸ“Š Evaluation Metrics")
    st.table(pd.DataFrame.from_dict(eval_results, orient='index', columns=['Value']))

    # 6. Visualization
    if X.shape[1] > 2:
        pca = PCA(n_components=2)
        X2 = pca.fit_transform(X)
        centers2 = pca.transform(centers) if centers is not None else None
        st.write(f"PCA Explained Variance Ratio: {pca.explained_variance_ratio_}")
    else:
        X2, centers2 = X, centers

    # Create meshgrid for decision boundary (chá»‰ Ã¡p dá»¥ng cho K-Means)
    if method == "K-Means":
        x_min, x_max = X2[:, 0].min() - 1, X2[:, 0].max() + 1
        y_min, y_max = X2[:, 1].min() - 1, X2[:, 1].max() + 1
        xx, yy = np.meshgrid(
            np.linspace(x_min, x_max, 200),
            np.linspace(y_min, y_max, 200)
        )
        grid = np.c_[xx.ravel(), yy.ravel()]
        grid_orig = pca.inverse_transform(grid) if X.shape[1] > 2 else grid

        if algo == "Custom":
            dist_grid = np.linalg.norm(grid_orig[:, None, :] - centers[None, :, :], axis=2)
            labels_grid = np.argmin(dist_grid, axis=1)
        else:
            labels_grid = km.predict(grid_orig)
    else:
        # DBSCAN khÃ´ng cÃ³ tÃ¢m cá»¥m, khÃ´ng váº½ ranh giá»›i quyáº¿t Ä‘á»‹nh
        xx, yy, labels_grid = None, None, None

    # Plot clustering results (chá»‰ giá»¯ 1 biá»ƒu Ä‘á»“)
    fig, ax = plt.subplots(figsize=(8, 6))  # Chá»‰ táº¡o 1 subplot
    if method == "K-Means":
        cmap = plt.cm.get_cmap('tab10', k)
    else:
        # DBSCAN cÃ³ thá»ƒ cÃ³ nhÃ£n -1 (nhiá»…u), cáº§n tÃ­nh sá»‘ cá»¥m thá»±c táº¿
        unique_labels = np.unique(labels)
        k = len(unique_labels) - (1 if -1 in unique_labels else 0)
        cmap = plt.cm.get_cmap('tab10', max(k, 1))

    # Decision Boundary (chá»‰ cho K-Means)
    if method == "K-Means":
        plot_decision_boundary(ax, xx, yy, labels_grid, cmap)
        ax.scatter(X2[:, 0], X2[:, 1], c=labels, edgecolor='k', s=30, cmap=cmap)
        ax.scatter(centers2[:, 0], centers2[:, 1], marker='X', s=200, c='red', label='Centroids')
        ax.set_title("Clustering Results with Decision Boundary")
        patches = [mpatches.Patch(color=cmap(i), label=f'Cluster {i}') for i in range(k)]
        legend = ax.legend(handles=patches + [mpatches.Patch(color='red', label='Centroids')],
                           loc='best')
        ax.add_artist(legend)
    else:
        ax.scatter(X2[:, 0], X2[:, 1], c=labels, edgecolor='k', s=30, cmap=cmap)
        ax.set_title("DBSCAN Clustering Results")
        unique_labels = np.unique(labels)
        patches = []
        for label in unique_labels:
            if label == -1:
                patches.append(mpatches.Patch(color='black', label='Noise'))
            else:
                patches.append(mpatches.Patch(color=cmap(label), label=f'Cluster {label}'))
        legend = ax.legend(handles=patches, loc='best')
        ax.add_artist(legend)
    ax.set_xlabel("Feature 1 (PCA)")
    ax.set_ylabel("Feature 2 (PCA)")

    st.pyplot(fig)

    # 7. User explanation
    explanation = """
    **Giáº£i thÃ­ch biá»ƒu Ä‘á»“**:
    """
    if method == "K-Means":
        explanation += """
    - **VÃ¹ng mÃ u**: Má»—i vÃ¹ng biá»ƒu thá»‹ khu vá»±c khÃ´ng gian mÃ  táº¥t cáº£ cÃ¡c Ä‘iá»ƒm trong Ä‘Ã³ sáº½ Ä‘Æ°á»£c gÃ¡n vÃ o cÃ¹ng má»™t cá»¥m.
      - VÃ¹ng **lá»›n nháº¥t** cho tháº¥y cluster Ä‘Ã³ cÃ³ pháº¡m vi phÃ¢n bá»‘ rá»™ng vÃ  centroid cÃ¡ch xa cÃ¡c cluster khÃ¡c, nghÄ©a lÃ  mÃ´ hÃ¬nh gÃ¡n nhiá»u khÃ´ng gian cho cluster nÃ y.
      - VÃ¹ng **nhá» nháº¥t** cho tháº¥y cluster táº­p trung cháº·t cháº½ quanh centroid, chiáº¿m Ã­t khÃ´ng gian hÆ¡n.
    - **Äiá»ƒm mÃ u**: Vá»‹ trÃ­ cÃ¡c máº«u dá»¯ liá»‡u, mÃ u sáº¯c thá»ƒ hiá»‡n cá»¥m Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n; máº­t Ä‘á»™ Ä‘iá»ƒm trong má»—i vÃ¹ng cÃ²n pháº£n Ã¡nh Ä‘á»™ dÃ y Ä‘áº·c (density) cá»§a dá»¯ liá»‡u.
    - **Chá»¯ X Ä‘á»**: Vá»‹ trÃ­ trung tÃ¢m (centroid) cá»§a tá»«ng cá»¥m; Ä‘Ã¢y lÃ  Ä‘iá»ƒm trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c dá»¯ liá»‡u trong cluster.
    - **Ã nghÄ©a thá»±c tiá»…n**:
      + Cluster cÃ³ **vÃ¹ng lá»›n** thÆ°á»ng bao quÃ¡t cÃ¡c khÃ¡ch hÃ ng vá»›i hÃ nh vi/phÃ¢n phá»‘i Ä‘a dáº¡ng hÆ¡n (vÃ­ dá»¥: nhÃ³m khÃ¡ch hÃ ng cÃ³ thu nháº­p vÃ  chi tiÃªu trung bÃ¬nh).
      + Cluster cÃ³ **vÃ¹ng nhá»** thÆ°á»ng Ä‘áº¡i diá»‡n cho nhÃ³m khÃ¡ch hÃ ng cÃ³ tÃ­nh cháº¥t Ä‘á»“ng nháº¥t vÃ  táº­p trung (vÃ­ dá»¥: nhÃ³m khÃ¡ch hÃ ng tráº» chi tiÃªu cao).
    """
    else:
        explanation += """
    - **Äiá»ƒm mÃ u**: Vá»‹ trÃ­ cÃ¡c máº«u dá»¯ liá»‡u, mÃ u sáº¯c thá»ƒ hiá»‡n cá»¥m Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n. Äiá»ƒm mÃ u Ä‘en (náº¿u cÃ³) biá»ƒu thá»‹ nhiá»…u (noise), tá»©c lÃ  cÃ¡c Ä‘iá»ƒm khÃ´ng thuá»™c cá»¥m nÃ o.
    - **KhÃ´ng cÃ³ ranh giá»›i quyáº¿t Ä‘á»‹nh**: DBSCAN khÃ´ng táº¡o tÃ¢m cá»¥m, nÃªn khÃ´ng thá»ƒ váº½ ranh giá»›i nhÆ° K-Means.
    - **Ã nghÄ©a thá»±c tiá»…n**:
      + CÃ¡c cá»¥m Ä‘Æ°á»£c táº¡o bá»Ÿi DBSCAN thÆ°á»ng cÃ³ hÃ¬nh dáº¡ng báº¥t ká»³, phÃ¹ há»£p Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c nhÃ³m khÃ¡ch hÃ ng cÃ³ hÃ nh vi Ä‘áº·c biá»‡t.
      + CÃ¡c Ä‘iá»ƒm nhiá»…u (noise) cÃ³ thá»ƒ lÃ  cÃ¡c khÃ¡ch hÃ ng khÃ´ng thuá»™c nhÃ³m nÃ o, cáº§n phÃ¢n tÃ­ch thÃªm Ä‘á»ƒ hiá»ƒu nguyÃªn nhÃ¢n.
    """
    st.markdown(explanation)

    # 8. Cluster summary
    st.subheader("ğŸ“‹ Cluster Summary")
    df["Cluster"] = labels
    cluster_summary = df.groupby("Cluster")[cols].mean()
    st.table(cluster_summary)

    # 9. Additional information for DBSCAN
    if method == "DBSCAN":
        unique_labels = np.unique(labels)
        num_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)
        num_noise = np.sum(labels == -1)
        st.write(f"**Number of Clusters**: {num_clusters}")
        st.write(f"**Number of Noise Points**: {num_noise} (out of {len(labels)} points)")

    # 10. Hiá»ƒn thá»‹ sÆ¡ Ä‘á»“ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh Ä‘Æ°á»£c chá»n
    st.subheader(f"ğŸ“ˆ Biá»ƒu Ä‘á»“ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh {method_name}")
    visualizer = ClusterVisualizer()
    values = [eval_results.get(metric, None) for metric in metrics_to_compare]
    # Váº½ biá»ƒu Ä‘á»“ vÃ  hiá»ƒn thá»‹ trong Streamlit
    fig, ax = plt.subplots(figsize=(8, 6))
    valid_metrics = []
    valid_values = []
    for metric, value in zip(metrics_to_compare, values):
        if value is not None:
            valid_metrics.append(metric)
            valid_values.append(value)

    if valid_metrics:
        bars = ax.bar(valid_metrics, valid_values, color=plt.cm.tab10(0))
        ax.set_title(f"ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh {method_name} theo cÃ¡c Ä‘á»™ Ä‘o")
        ax.set_xlabel("Äá»™ Ä‘o Ä‘Ã¡nh giÃ¡")
        ax.set_ylabel("GiÃ¡ trá»‹")
        # Äáº·t giá»›i háº¡n trá»¥c y tÃ¹y thuá»™c vÃ o giÃ¡ trá»‹ lá»›n nháº¥t
        max_value = max(valid_values)
        if max_value <= 0.5:
            ax.set_ylim(0, 0.5)
        elif max_value <= 2.0:
            ax.set_ylim(0, 2.0)
        else:
            ax.set_ylim(0, max_value * 1.1)
        # ThÃªm giÃ¡ trá»‹ lÃªn trÃªn má»—i cá»™t
        for bar, value in zip(bars, valid_values):
            ax.text(bar.get_x() + bar.get_width() / 2, value, f"{value:.4f}",
                    ha='center', va='bottom')
        # Xoay nhÃ£n trá»¥c x Ä‘á»ƒ dá»… Ä‘á»c
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        st.pyplot(fig)
    else:
        st.write("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ váº½ sÆ¡ Ä‘á»“ Ä‘Ã¡nh giÃ¡ cho mÃ´ hÃ¬nh nÃ y.")